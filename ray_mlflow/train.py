import ray
from ray import tune
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
import pandas as pd
import numpy as np
import mlflow
from ray_mlflow.model_utils import setup_mlflow, register_best_model

def load_data():
    """
    Loads feature data from the Parquet files generated by the Spark job,
    and creates dummy labels for training.
    """
    try:
        # Read all parquet files in the directory
        feature_df = pd.read_parquet('data/processed/features')
    except Exception as e:
        print(f"Could not read parquet files: {e}. Using dummy data instead.")
        # Fallback to dummy data if no features are generated yet
        return train_test_split(np.random.rand(100, 2), np.random.randint(0, 2, 100), test_size=0.2)
        
    # Drop user_id as it's an identifier, not a feature
    feature_df = feature_df.drop(columns=['user_id'])
    
    # In a real scenario, you would have a 'is_fraud' column from your ground truth data.
    # Here, we create dummy labels for demonstration.
    # Let's assume high average amount OR high transaction count is suspicious.
    feature_df['is_fraud'] = np.where(
        (feature_df['avg_amount'] > 500) | (feature_df['txn_count'] > 5), 1, 0
    )

    X = feature_df.drop(columns=['is_fraud'])
    y = feature_df['is_fraud']
    
    return train_test_split(X, y, test_size=0.2, stratify=y if np.any(y) else None)

def train_model(config):
    # MLflow tracking is managed by Ray Tune's `MLflowLoggerCallback`
    X_train, X_test, y_train, y_test = load_data()
    
    model = RandomForestClassifier(
        n_estimators=config["n_estimators"],
        max_depth=config["max_depth"],
        random_state=42
    )
    model.fit(X_train, y_train)
    
    accuracy = model.score(X_test, y_test)
    
    # Log parameters and metrics to MLflow
    mlflow.log_param("n_estimators", config["n_estimators"])
    mlflow.log_param("max_depth", config["max_depth"])
    mlflow.log_metric("accuracy", accuracy)
    
    # Log the model with a signature
    from mlflow.models.signature import infer_signature
    signature = infer_signature(X_train, model.predict(X_train))
    mlflow.sklearn.log_model(model, "fraud_detection_model", signature=signature)
    
    # Report metrics to Ray Tune
    tune.report(accuracy=accuracy)

def main():
    model_name = setup_mlflow()
    ray.init(ignore_reinit_error=True)

    # Define the hyperparameter search space for Ray Tune
    search_space = {
        "n_estimators": tune.grid_search([50, 100]),
        "max_depth": tune.choice([10, 20])
    }

    # Run the hyperparameter tuning job
    analysis = tune.run(
        train_model,
        config=search_space,
        metric="accuracy",
        mode="max",
        num_samples=1, # In a real run, you'd use more samples
        resources_per_trial={'cpu': 1}
    )

    print("Best hyperparameters found were: ", analysis.best_config)
    register_best_model(analysis, model_name)

    ray.shutdown()

if __name__ == "__main__":
    main()
